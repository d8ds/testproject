Ah, perfect! This is much clearer and actually a **stronger narrative structure**. You discovered rolling works early with the length signal, then applied it systematically to everything else. Let me restructure:

---

## **Revised Narrative: "Discovery → Systematic Application"**

---

## **Act 1: The Discovery (4-5 minutes)**

### **Slide 3: Length Signal - The Methodological Breakthrough**

**Title:** "Document Length: Three Approaches to Signal Construction"

**The Setup:**
"We started with the most obvious signal: document length. But *how* you measure it matters profoundly."

**Show Three Approaches:**

| Method | Measurement | Hypothesis | Result |
|--------|-------------|------------|---------|
| **Point-based** | Current filing length | "Verbose filings signal uncertainty" | IC: 0.02, Sharpe: 0.4 |
| **Delta-based** | Length change vs previous filing | "Increasing verbosity signals problems" | IC: 0.03, Sharpe: 0.5 |
| **Rolling-based** | Rolling sum over last N filings | "Persistent verbosity reveals behavior" | IC: 0.06, Sharpe: 1.2 |

**Visual: Side-by-Side Quintile Charts**
- Three panels showing quintile spreads for each method
- Rolling has the cleanest, strongest monotonic relationship

**The Key Finding:**
> "Rolling sum outperformed by **2-3x**. This wasn't marginal—it was definitive. Point-based: noisy. Delta-based: better but still reactive. Rolling-based: captures **persistent disclosure behavior**."

**Why Rolling Sum for Length?**
- Point: "This filing is 5,000 words" → Single observation, high variance
- Delta: "500 words longer than last time" → Still event-focused
- **Rolling Sum: "20,000 words across last 6 filings" → Cumulative disclosure burden**

**The Insight:**
> "We're not measuring a single filing's length. We're measuring **how much management has been talking lately**. High cumulative disclosure burden over rolling windows signals sustained uncertainty or complexity."

**The Decision:**
"This worked so well, we applied rolling aggregation to **every subsequent signal**."

---

## **Act 2: Systematic Application - Content Signals (4-5 minutes)**

**The Transition:**
"Having discovered rolling aggregation's power, we systematically applied it to all content-based features..."

### **Slide 4: Quality-Adjusted Length (Rolling)**

**Title:** "Beyond Volume: Rolling Quality-Adjusted Disclosure"

**The Refinement:**
- Apply sentence quality filter to remove boilerplate
- Calculate rolling sum of **quality-adjusted** word count
- "Not just how much they're saying, but how much **substance** they're producing"

**Measurement:**
```
Rolling_Quality_Length = Σ(Filtered_Length[t-5:t])
```

**Performance:**
- IC: 0.07, Sharpe: 1.3
- Improvement over rolling raw length: "Filtering noise adds another 15-20% to performance"

**The Behavior:**
"Companies with persistently high **quality-adjusted** disclosure burden are managing complexity or uncertainty with substantive content—not just padding documents."

---

### **Slide 5: Numerical Density (Rolling)**

**Title:** "Specificity Patterns: Rolling Numerical Density"

**The Concept:**
- Count/weight numbers in each filing
- Calculate rolling average or rolling sum
- "Persistent specificity vs persistent vagueness"

**Measurement:**
```
Rolling_Num_Density = Σ(Number_Count[t-5:t]) / Σ(Word_Count[t-5:t])

Or: Rolling_Num_Sum = Σ(Weighted_Number_Count[t-5:t])
```

**The Behavioral Classification:**

| Pattern | Interpretation | Signal |
|---------|----------------|--------|
| Consistently High Density | Habitual specificity → Confidence & transparency | Positive |
| Consistently Low Density | Habitual vagueness → Hiding behind generalities | Negative |
| Declining Density | Shift from specific to vague → Deteriorating situation | Negative |
| Increasing Density | Shift from vague to specific → Improving transparency | Positive |

**Performance:**
- IC: 0.05, Sharpe: 1.0
- "Relatively orthogonal to length signals (correlation ~0.3)"

**The Insight:**
> "Some management teams **habitually show their work** with numbers. Others **habitually hide behind adjectives**. Rolling windows reveal these persistent communication styles."

---

## **Act 3: Structural Signals (3-4 minutes)**

**The Transition:**
"We've analyzed content volume, quality, and specificity—all with rolling aggregation. Now let's examine document **structure**..."

### **Slide 6A: Section Count (Rolling)**

**Title:** "Document Complexity: Rolling Section Patterns"

**The Measurement:**
```
Rolling_Section_Count = Average(Section_Count[t-5:t])

Or: Rolling_Section_Sum = Σ(Section_Count[t-5:t])
```

**The Pattern Recognition:**

**Low Rolling Section Count (< 3 average):**
- Consistently focused disclosures
- Single-event filers
- Cleaner information environment

**High Rolling Section Count (> 6 average):**
- Consistently complex situations
- Multi-event filers
- OR habitual fragmenters (obfuscation strategy)

**Performance:**
- IC: 0.05, Sharpe: 0.9

**Example:**
"Company A: Last 6 filings averaged 2.3 sections → Focused, transparent
Company B: Last 6 filings averaged 7.8 sections → Complex or fragmented"

---

### **Slide 6B: Material Section Length (Rolling)**

**Title:** "Disclosure Depth: Where Does Management Focus?"

**The Measurement:**
```
Rolling_Material_Length = Average(Material_Section_Length[t-5:t])

Or: Rolling_Depth_Ratio = Σ(Material_Length[t-5:t]) / Σ(Total_Length[t-5:t])
```

**The 2x2 Matrix (Now With Rolling Context):**

```
                        Low Rolling         High Rolling
                        Section Count       Section Count
                        ------------------|------------------
High Rolling            "Focused &         | "Comprehensive
Material                Thorough"          | but Complex"
Length                  Persistent depth   | High effort,
                        on key issues      | many topics
                        [BEST]             | [NEUTRAL/OK]
                        ------------------|------------------
Low Rolling             "Consistently      | "Habitual
Material                Minimal"           | Fragmenters"
Length                  Low disclosure     | Spread thin,
                        effort             | avoid depth
                        [NEUTRAL/NEG]      | [WORST]
```

**Performance:**
- IC: 0.06, Sharpe: 1.1
- Strong interaction effect with section count

**The Classification:**
> "We can now classify companies by their **persistent structural behavior**:
> - Deep-divers: Always thorough
> - Fragmenters: Always scattered
> - Minimalists: Always terse
> 
> These are stable corporate traits, not random choices."

---

## **Act 4: Behavioral Metadata (2-3 minutes)**

### **Slide 7: Filing Delay (Rolling)**

**Title:** "The Timing Signal: Rolling Filing Behavior"

**The Measurement:**
```
Rolling_Avg_Delay = Average(Filing_Delay[t-5:t])

Where Filing_Delay = Filing_Date - Event_Date (in business days, 0-4)
```

**The Behavioral Spectrum:**

| Rolling Average Delay | Behavior Pattern | Interpretation |
|----------------------|------------------|----------------|
| < 1 day | Habitually prompt | Confident, transparent, proactive |
| 1-2 days | Moderate | Standard practice |
| 2-3 days | Consistently slow | Cautious, requires review |
| > 3 days | Chronic delayers | Defensive, uncomfortable with disclosure |

**The Power:**
"This is **pure behavioral signal**—no text analysis needed. Management reveals their state of mind through **actions**, not words."

**Performance:**
- IC: 0.08, Sharpe: 1.3
- Often the strongest standalone signal
- Low correlation with content signals (~0.10-0.15)

**The Insight:**
> "Individual filings can be delayed for innocent reasons. But companies that **chronically delay** are revealing persistent discomfort with disclosure. That discomfort predicts negative returns."

**Possible Enhancement:**
- Interaction with day-of-week: "Companies that consistently file on Friday evenings"
- Interaction with market conditions: "Delaying more during earnings season"

---

## **Act 5: Integration & The Universal Principle (3-4 minutes)**

### **Slide 8: The Complete Signal Framework**

**Title:** "From Discovery to System: Rolling-Based Behavioral Signals"

**Visual: The Signal Architecture**

```
ROLLING AGGREGATION FRAMEWORK
(Discovery from length signal → Applied to all features)

CONTENT DIMENSION
├── Volume ──────────────── Rolling Sum of Length
├── Quality ─────────────── Rolling Sum of Filtered Length  
└── Specificity ─────────── Rolling Numerical Density

STRUCTURAL DIMENSION
├── Complexity ──────────── Rolling Avg Section Count
└── Focus ───────────────── Rolling Avg Material Length

BEHAVIORAL DIMENSION
└── Timing ──────────────── Rolling Avg Filing Delay
```

**The Unified Performance Table:**

| Signal | Rolling IC | Rolling Sharpe | Correlation with Others |
|--------|-----------|----------------|------------------------|
| Rolling Length Sum | 0.06 | 1.2 | Baseline |
| Rolling Quality Length | 0.07 | 1.3 | 0.75 with length |
| Rolling Num Density | 0.05 | 1.0 | 0.30 with length |
| Rolling Section Count | 0.05 | 0.9 | 0.25 with length |
| Rolling Material Length | 0.06 | 1.1 | 0.35 with section count |
| Rolling Delay | 0.08 | 1.3 | 0.12 with length |

**Key Observations:**
1. All signals benefit from rolling aggregation
2. Relatively low inter-signal correlations (0.10-0.35) → orthogonal information
3. Delay signal has lowest correlation → pure behavioral vs content-based

---

### **Slide 9: Why Rolling Aggregation Works**

**Title:** "The Behavioral Paradigm: Traits vs Events"

**Two-Column Comparison:**

| Event-Based Thinking | Behavioral Thinking (Rolling) |
|---------------------|------------------------------|
| "What's in this filing?" | "What's this company's disclosure style?" |
| Reacts to individual events | Identifies persistent patterns |
| High variance (noisy) | Low variance (smooth) |
| Short-term signal decay | Persistent signal |
| Treats each filing as independent | Recognizes management consistency |
| Typical IC: 0.02-0.03 | Typical IC: 0.05-0.08 |

**The Three Mechanisms:**

**1. Noise Reduction**
```
Single Filing Length: 3000, 7000, 4000, 8000, 5000, 6000
→ High variance, hard to interpret

Rolling Sum: 18K, 22K, 24K, 25K, 28K, 29K
→ Clear upward trend, interpretable pattern
```

**2. Behavioral Persistence**
- Management styles are sticky (corporate culture, legal practices, IR strategies)
- Autocorrelation of rolling signals: 0.6-0.8 vs point signals: 0.1-0.2
- "Disclosure behavior is a **trait**, not a random variable"

**3. Lower Turnover**
- Point signals flip frequently → High transaction costs
- Rolling signals change gradually → Lower turnover, higher capacity
- "More tradeable AND more profitable"

**Statistical Evidence:**

Show an autocorrelation function (ACF) chart:
- X-axis: Lag (months)
- Y-axis: Autocorrelation
- Blue line: Point-based length signal (decays quickly to 0)
- Red line: Rolling-based length signal (stays high at 0.6-0.7)

"Rolling signals have 4-5x higher persistence → easier to model, predict, and trade"

---

### **Slide 10: The Composite Signal**

**Title:** "Integration: The Behavioral Fingerprint"

**The Combination Approach:**

**Option 1: Equal-Weighted Composite**
```
Composite_Score = Rank(Rolling_Length) + Rank(Rolling_Quality) + 
                  Rank(Rolling_NumDensity) + Rank(Rolling_Sections) +
                  Rank(Rolling_MaterialLen) + Rank(Rolling_Delay)
```

**Option 2: Optimized Weights (PCA or IC-weighted)**
```
Composite_Score = 0.20×Rolling_Length + 0.25×Rolling_Quality +
                  0.15×Rolling_NumDensity + 0.10×Rolling_Sections +
                  0.15×Rolling_MaterialLen + 0.15×Rolling_Delay
```

**Performance:**

| Approach | IC | Sharpe | Turnover | Hit Rate |
|----------|-----|--------|----------|----------|
| Best Single Signal (Rolling Delay) | 0.08 | 1.3 | Medium | 55% |
| Equal-Weight Composite | 0.10 | 1.6 | Medium-Low | 57% |
| Optimized Composite | 0.12 | 1.8 | Medium-Low | 58% |

**Quintile Spread (Monthly Returns):**
```
Q1 (Best):    +1.2%
Q2:           +0.4%
Q3:            0.0%
Q4:           -0.5%
Q5 (Worst):   -1.5%

Long-Short Spread: 2.7% per month (t-stat > 4.0)
```

**The Visual: Spider/Radar Chart**

Compare two actual companies across all six rolling dimensions:

**Company A (Good Disclosure Behavior):**
- Low rolling length (efficient)
- High rolling quality (substantive)
- High rolling numerical density (specific)
- Low rolling section count (focused)
- High rolling material length (thorough)
- Low rolling delay (prompt)

**Company B (Poor Disclosure Behavior):**
- High rolling length (verbose)
- Low rolling quality (boilerplate-heavy)
- Low rolling numerical density (vague)
- High rolling section count (fragmented)
- Low rolling material length (shallow)
- High rolling delay (slow)

**The Message:**
> "These aren't six separate signals—they're six **complementary views** of the same underlying trait: management's disclosure behavior. Together, they create a comprehensive behavioral fingerprint."

---

## **Act 6: Implications & Next Steps (2 minutes)**

### **Slide 11: Key Takeaways**

**The Three-Level Discovery:**

**Level 1: The Methodological Insight**
✓ Rolling aggregation transforms noisy events into stable behavioral signals
✓ 2-3x improvement across all signal types
✓ Applicable beyond 8-Ks to any event-driven alternative data

**Level 2: The Content-Structure-Behavior Framework**
✓ Content signals: What they say and how specifically
✓ Structural signals: How they organize information
✓ Behavioral signals: When they say it and with what consistency
✓ Together: Orthogonal dimensions capturing holistic disclosure behavior

**Level 3: The Practical Edge**
✓ Composite signal: IC 0.10-0.12, Sharpe 1.6-1.8
✓ Monthly long-short spread: 2.5-3.0%
✓ Moderate turnover → high capacity strategy
✓ Persistent signals → stable performance across time

---

### **Slide 12: Next Steps & Research Agenda**

**Immediate Enhancements:**

1. **Orthogonalization & Factor Analysis**
   - Current high correlation between length and quality length (0.75)
   - Apply PCA or factor models to extract independent components
   - Potentially improve IC by 10-15%

2. **Dynamic Window Selection**
   - Currently using fixed 6-filing window
   - Test adaptive windows based on filing frequency
   - Exponentially-weighted moving averages for recency weighting

3. **Event-Type Segmentation**
   - Different Item types may have different behavioral patterns
   - M&A disclosures (Item 1.01) vs Results (Item 2.02) vs Changes in Control
   - Segment models by event category

**Advanced Directions:**

4. **Cross-Sectional Variations**
   - Sector-specific norms (tech vs utilities have different filing patterns)
   - Size-adjusted signals (small caps vs large caps)
   - Volatility regime conditioning

5. **Interaction Effects**
   - Market conditions: How do signals perform in different regimes?
   - Momentum interaction: Combine with price signals
   - Earnings interaction: Filing behavior around earnings announcements

6. **Text-Based Enhancements**
   - Sentiment analysis on quality-filtered content
   - Topic modeling to identify disclosure themes
   - Readability/complexity scores
   - Management tone consistency over rolling windows

---

## **Complete 15-Minute Flow**

```
PRESENTATION STRUCTURE

Opening (2 min)
├── Slide 1: Title & Thesis
└── Slide 2: The Opportunity (8-K vs 10-K/Q comparison)

The Discovery (4 min)
└── Slide 3: Length Signal - Point vs Delta vs Rolling
            "Rolling wins 2-3x → Apply to everything"

Content Signals (3 min)
├── Slide 4: Quality-Adjusted Length (Rolling) [1 min]
└── Slide 5: Numerical Density (Rolling) [1 min]
            Brief, show performance, emphasize patterns

Structural Signals (2.5 min)
├── Slide 6A: Section Count (Rolling) [1 min]
└── Slide 6B: Material Section Length (Rolling) [1.5 min]
            Show 2x2 matrix, behavioral classification

Behavioral Signal (1.5 min)
└── Slide 7: Filing Delay (Rolling)
            Pure behavioral, strongest signal

Integration (3 min)
├── Slide 8: Complete Framework & Performance Table [1.5 min]
├── Slide 9: Why Rolling Works (Mechanisms) [1 min]
└── Slide 10: Composite Signal & Spider Chart [0.5 min]

Closing (2 min)
├── Slide 11: Key Takeaways [1 min]
└── Slide 12: Next Steps [1 min]

TOTAL: 15 minutes
```

---

## **Key Messaging Throughout**

**Mantras to repeat:**

1. "Rolling aggregation captures **persistent behavior**, not random events"
2. "We're trading on **management disclosure styles**, not individual filing reactions"
3. "Across all dimensions—content, structure, behavior—rolling dominates"
4. "Low inter-signal correlation means each adds **unique information**"
5. "This isn't feature engineering—it's **systematic behavioral analysis**"

---

## **Slide 3 Deep Dive: The Discovery Moment**

Since this is your pivotal slide, let's make it exceptional:

**Visual Layout:**

**Top Third: The Question**
"How should we measure document length?"

**Middle Third: Three Panels (Side-by-Side)**

**Panel 1: Point-Based**
```
Measurement: Length[t]
Example: 5,200 words

Quintile Returns:
Q1: -0.3%
Q2: -0.1%
Q3:  0.0%
Q4:  0.2%
Q5:  0.3%
Spread: 0.6%

IC: 0.02
Sharpe: 0.4
```

**Panel 2: Delta-Based**
```
Measurement: Length[t] - Length[t-1]
Example: +800 words

Quintile Returns:
Q1: -0.4%
Q2: -0.2%
Q3:  0.0%
Q4:  0.3%
Q5:  0.5%
Spread: 0.9%

IC: 0.03
Sharpe: 0.5
```

**Panel 3: Rolling-Based**
```
Measurement: Σ(Length[t-5:t])
Example: 28,400 words (6-filing sum)

Quintile Returns:
Q1: -0.8%
Q2: -0.3%
Q3:  0.0%
Q4:  0.4%
Q5:  1.0%
Spread: 1.8%

IC: 0.06
Sharpe: 1.2
```

**Bottom Third: The Insight**

> "Rolling sum outperformed by **3x**. The breakthrough: We're not measuring a single filing's verbosity—we're measuring **cumulative disclosure burden** over time. High rolling length reveals sustained uncertainty or complexity, which persistently predicts negative returns."

**The Decision Box:**
```
✓ DECISION: Use rolling aggregation for all subsequent signals
  Rationale: Transforms noisy events → stable behavioral traits
```

---

This structure tells a clear story: **"We discovered something powerful early (rolling), then systematically applied it to build a comprehensive framework."** 

Much cleaner than presenting everything twice (point then rolling). The audience learns your methodology in the first 4 minutes, then watches you systematically construct a multi-dimensional behavioral model.

Would you like me to elaborate on any specific slides or create detailed visualizations for particular comparisons?
